"""
MemoryAnalyzer - AI-–∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º
–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∫–∞–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–ª–µ–¥—É–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –∏
–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
"""

import asyncio
import logging
from typing import Dict, Optional, Tuple
from google import genai

logger = logging.getLogger(__name__)


class MemoryAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–∞–º—è—Ç–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Google Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è,
    –∫–∞–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–ª–µ–¥—É–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    """
    
    def __init__(self, gemini_api_key: str, model_name: str = "models/gemini-2.5-flash"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏.
        
        Args:
            gemini_api_key: API –∫–ª—é—á –¥–ª—è Google Gemini
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Gemini –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gemini-2.5-flash-lite)
        """
        self.gemini_api_key = gemini_api_key
        self.model_name = model_name
        self.client = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Gemini (–Ω–æ–≤—ã–π SDK google-genai)
        try:
            self.client = genai.Client(
                http_options={"api_version": "v1beta"},
                api_key=gemini_api_key,
            )
            logger.info(f"‚úÖ MemoryAnalyzer initialized with model {model_name}")
        except Exception as e:
            logger.error(f"‚ùå MemoryAnalyzer initialization error: {e}")
            self.client = None
    
    async def analyze_conversation(
        self, 
        user_prompt: str, 
        assistant_response: str,
        conversation_context: Optional[str] = None
    ) -> Tuple[str, str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—É—é –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é –ø–∞–º—è—Ç—å.
        
        Args:
            user_prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            assistant_response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            conversation_context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            
        Returns:
            Tuple[str, str]: (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è_–ø–∞–º—è—Ç—å, –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è_–ø–∞–º—è—Ç—å)
        """
        if not self.client:
            logger.warning("‚ö†Ô∏è Gemini model is not available, returning empty memory")
            return "", ""
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_prompt = self._create_analysis_prompt(
                user_prompt, 
                assistant_response, 
                conversation_context
            )
            
            # –í—ã–∑—ã–≤–∞–µ–º Gemini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            short_memory, long_memory = await self._call_gemini_analysis(analysis_prompt)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            logger.info(f"üß† Memory analysis completed:")
            logger.info(f"   Short Memory: {len(short_memory)} characters")
            logger.info(f"   Long Memory: {len(long_memory)} characters")
            
            return short_memory, long_memory
            
        except Exception as e:
            logger.error(f"‚ùå Conversation analysis error: {e}")
            return "", ""
    
    def _create_analysis_prompt(
        self, 
        user_prompt: str, 
        assistant_response: str,
        conversation_context: Optional[str] = None
    ) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
        
        Args:
            user_prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            assistant_response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            conversation_context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            
        Returns:
            str: –ü—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        """
        context_part = ""
        if conversation_context:
            context_part = f"\n\nConversation context:\n{conversation_context}"
        
        return f"""**You are an assistant responsible for managing memory. You have two types of memory: Short Memory and Long Memory.**

**CRITICAL: You MUST ALWAYS respond in this EXACT format:**
```
SHORT MEMORY: [content to save to short memory or "none"]
LONG MEMORY: [content to save to long memory or "none"]
```

**Short Memory** is temporary memory that stores information about the current conversation and recent interactions. It is updated frequently and can be cleared after a period of inactivity.

**Long Memory** is long-term memory that stores only important information about the user, their preferences, habits, and key events.

**You are provided with:**
1. **User's request** ‚Äî the current request sent by the user.
2. **LLM's response** ‚Äî the response generated based on the user's request.

**Your task:**
1. Analyze the user's request and the LLM's response.
2. Determine if there is any information that needs to be added to Short Memory and/or Long Memory.
3. **ALWAYS respond in the exact format above.**

**Rules for adding information to memory:**

- **Short Memory:**
  - Current conversation context, temporary preferences, ongoing tasks.
  - Example: "User introduced themselves as Sergei, developer from Moscow"

- **Long Memory:**
  - **Personal data**: Name, surname, nickname, profession, location.
  - **Preferences and habits**: Important likes/dislikes, regular habits.
  - **Important events**: Birthdays, anniversaries, future plans.
  - **Professional data**: Job, skills, work preferences.

**Examples of what goes to Long Memory:**
- "User's name is Sergei"
- "User is a developer from Moscow"
- "User prefers quiet working environments"
- **ALWAYS save personal information like names, professions, locations**
- **ALWAYS save when user introduces themselves**

**What is NOT added to Long Memory:**
- Temporary information (e.g., "Today I want pizza")
- One-time mentions without importance
- General information unrelated to the user

**IMPORTANT: When a user introduces themselves (name, profession, location), this information MUST go to Long Memory as it's essential for personalization!**

**EXAMPLE ANALYSIS:**
If user says "–ú–µ–Ω—è –∑–æ–≤—É—Ç –°–µ—Ä–≥–µ–π, —è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑ –ú–æ—Å–∫–≤—ã", you MUST respond:
```
SHORT MEMORY: User introduced themselves in Russian
LONG MEMORY: User's name is Sergei, they are a developer from Moscow
```

**REMEMBER: ALWAYS use the exact format with SHORT MEMORY: and LONG MEMORY: labels!**

---

**ACTUAL CONVERSATION TO ANALYZE:**

**User's request:**
{user_prompt}

**LLM's response:**
{assistant_response}

**Now analyze this conversation and respond in the required format.**"""
    
    async def _call_gemini_analysis(self, analysis_prompt: str) -> Tuple[str, str]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
        
        Args:
            analysis_prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Tuple[str, str]: (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è_–ø–∞–º—è—Ç—å, –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è_–ø–∞–º—è—Ç—å)
        """
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç 10 —Å–µ–∫—É–Ω–¥
            async with asyncio.timeout(10.0):
                response = await asyncio.to_thread(
                    self.client.models.generate_content,
                    model=self.model_name,
                    contents=analysis_prompt,
                )

                text = getattr(response, "text", None)
                if text:
                    logger.info(f"üß† Received response from Gemini: {text[:200]}...")
                    return self._extract_memory_from_response(text)
                else:
                    logger.warning("‚ö†Ô∏è Gemini returned empty response")
                    return "", ""

        except asyncio.TimeoutError:
            logger.warning("‚è∞ Memory analysis timeout (10 sec)")
            return "", ""
        except Exception as e:
            logger.error(f"‚ùå Gemini call error: {e}")
            return "", ""
    
    def _extract_memory_from_response(self, response_text: str) -> Tuple[str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—É—é –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é –ø–∞–º—è—Ç—å –∏–∑ –æ—Ç–≤–µ—Ç–∞ Gemini.
        
        Args:
            response_text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini
            
        Returns:
            Tuple[str, str]: (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è_–ø–∞–º—è—Ç—å, –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è_–ø–∞–º—è—Ç—å)
        """
        try:
            lines = response_text.strip().split('\n')
            short_memory = ""
            long_memory = ""
            
            logger.info(f"üß† Analyzing Gemini response: {len(lines)} lines")
            logger.debug(f"üß† Full response: {response_text[:500]}...")
            
            for line in lines:
                line = line.strip()
                logger.debug(f"üß† Line: '{line}'")
                
                # üîß –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
                if line.startswith("SHORT MEMORY:"):
                    short_memory = line.replace("SHORT MEMORY:", "").strip()
                    logger.info(f"üß† Found short memory: '{short_memory}'")
                elif line.startswith("LONG MEMORY:"):
                    long_memory = line.replace("LONG MEMORY:", "").strip()
                    logger.info(f"üß† Found long memory: '{long_memory}'")
                # üîß Fallback: –∏—â–µ–º –±–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏—è
                elif line.startswith("SHORT MEMORY"):
                    short_memory = line.replace("SHORT MEMORY", "").strip()
                    if short_memory.startswith(":"):
                        short_memory = short_memory[1:].strip()
                    logger.info(f"üß† Found short memory (fallback): '{short_memory}'")
                elif line.startswith("LONG MEMORY"):
                    long_memory = line.replace("LONG MEMORY", "").strip()
                    if long_memory.startswith(":"):
                        long_memory = long_memory[1:].strip()
                    logger.info(f"üß† Found long memory (fallback): '{long_memory}'")
            
            # üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ "none" –∑–Ω–∞—á–µ–Ω–∏–π
            if short_memory.lower() == "none":
                short_memory = ""
            if long_memory.lower() == "none":
                long_memory = ""
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞–º—è—Ç–∏
            short_memory = short_memory[:200] if short_memory else ""
            long_memory = long_memory[:500] if long_memory else ""
            
            logger.info(f"üß† Final memory: short ({len(short_memory)} characters), long ({len(long_memory)} characters)")
            
            return short_memory, long_memory
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting memory from response: {e}")
            return "", ""
    
    async def is_available(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏.
        
        Returns:
            bool: True –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω
        """
        if not self.client:
            return False
        
        try:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
            async with asyncio.timeout(5.0):
                test_response = await asyncio.to_thread(
                    self.client.models.generate_content,
                    model=self.model_name,
                    contents="Test availability",
                )
                return getattr(test_response, "text", None) is not None
        except Exception:
            return False
    
    def get_status(self) -> Dict[str, any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø–∞–º—è—Ç–∏.
        
        Returns:
            Dict: –°—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        """
        return {
            "available": self.client is not None,
            "model_name": self.model_name,
            "gemini_configured": bool(self.gemini_api_key)
        }


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import os
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("‚ùå GEMINI_API_KEY is not set")
    else:
        print("‚úÖ MemoryAnalyzer is ready for real conversation analysis")
        print("üìù Use analyze_conversation() method with actual user prompts and responses")
