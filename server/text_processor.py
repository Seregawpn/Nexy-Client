import asyncio
import logging
import os
import re
from typing import AsyncGenerator, List

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from config import Config
from utils.text_utils import split_into_sentences, clean_text, is_sentence_complete

# üöÄ –ù–û–í–´–ô: Gemini Live API (–æ—Å–Ω–æ–≤–Ω–æ–π)
try:
    from google import genai
    from google.genai import types
    GEMINI_LIVE_AVAILABLE = True
except ImportError as e:
    GEMINI_LIVE_AVAILABLE = False

# üîÑ FALLBACK: LangChain + Google Gemini
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_core.messages import HumanMessage, SystemMessage
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    LANGCHAIN_AVAILABLE = False

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ---
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–ª—é—á–µ–π API
if not Config.GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY not found. Check config.env")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ API
if not GEMINI_LIVE_AVAILABLE and not LANGCHAIN_AVAILABLE:
    raise ImportError("Neither Gemini Live API nor LangChain are available. Install required dependencies.")

logger = logging.getLogger(__name__)
logger.info(f"üîß API Status: Live API={GEMINI_LIVE_AVAILABLE}, LangChain={LANGCHAIN_AVAILABLE}")

class TextProcessor:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Google Gemini Live API (–æ—Å–Ω–æ–≤–Ω–æ–π)
    –∏ LangChain + Google Gemini (fallback).
    
    üöÄ –û–°–ù–û–í–ù–û–ô: Gemini Live API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Google Search –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    üîÑ FALLBACK: LangChain –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ Live API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    
    üö® –í–ê–ñ–ù–û: System Prompt –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏ Live API
    """
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–º—è—Ç–∏
        self.memory_analyzer = None
        self.db_manager = None
        
        # ‚úÖ System Prompt –¥–ª—è –æ–±–æ–∏—Ö API
        self.base_system_instruction = (
            "Your name is Nexy."
            "You are a helpful assistant for blind and visually impaired users. "
            "IMPORTANT: ALWAYS respond in ENGLISH ONLY, regardless of the user's language. "
            "Answer on question, exactly what user wants to know or get. Be polite, friendly and funn, don't be rude and sad be very funny and happy. ALWAYS analyze screenshots when provided to help the user understand what's on their screen and derectly answer to the question without empty words.\n"
   
            
            "üéØ YOUR CAPABILITIES:\n\n"
            
            "üí¨ BASIC CONVERSATION - for:\n"
            "- General questions and explanations\n"
            "- How things work\n"
            "- Definitions and concepts\n"
            "- Historical facts\n"
            "- Scientific explanations\n"
            "- Simple advice and help\n\n"
            
            "üì± SCREEN ANALYSIS - ALWAYS when screenshot available:\n"
            "- ALWAYS analyze and describe what you see on the screen\n"
            "- DO NOT return JSON coordinates or technical image analysis\n"
            "- Simply describe what you see on screen in natural language\n"
            "- Focus on helping the user with their question\n"
            "- If you see any dangerous content, warn about it\n\n"
            "- Focus on elements, applications what is on screen, you need to help with navigation and current situation and position of elements on screen\n"
           
            
            "üîç MANDATORY GOOGLE SEARCH - ALWAYS USE for:\n"
            "- Latest news, current events, breaking news\n"
            "- Weather forecasts and current conditions\n"
            "- Stock prices, cryptocurrency rates, financial data\n"
            "- Movie ratings, restaurant reviews, hotel reviews\n"
            "- Product prices, shopping information\n"
            "- ANY question requiring up-to-date information\n"
            "- NEVER say 'I can't provide current information' - ALWAYS SEARCH FIRST\n"
            "- ALWAYS cite sources when using search results\n\n"
            
            "üìã RESPONSE RULES:\n"
            "- Answer briefly and clearly\n"
            "- Be friendly and helpful\n"
            "- Don't over-explain\n"
            "- Focus on what the user needs\n"
            
            "REMEMBER: Keep it simple, helpful and Use memory just in case if you need to use, it's really helpful and user asks something about it but otherwise don't use it. Analyze a screenshot just when you were asking about about a screenshot of this kind of question otherwise you need to answer exactly on the question\n\n"
            "üö® CRITICAL: For ANY question about news, current events, weather, prices, or recent information - you MUST use Google Search. Do NOT say you can't provide current information - search first!"
        )
        
        logger.info(f"‚úÖ base_system_instruction created: {len(self.base_system_instruction)} characters")
        
        try:
            # üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø GEMINI LIVE API (–æ—Å–Ω–æ–≤–Ω–æ–π)
            if GEMINI_LIVE_AVAILABLE:
                logger.info("üöÄ Initializing Gemini Live API (primary)")
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç Live API —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                self.live_client = genai.Client(
                    http_options={"api_version": "v1beta"},
                    api_key=Config.GEMINI_API_KEY,
                )
                
                # üîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø Live API —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ enum –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                self.live_config = types.LiveConnectConfig(
                    response_modalities=[types.Modality.TEXT],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º enum
                    media_resolution=types.MediaResolution.MEDIA_RESOLUTION_MEDIUM,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º enum
                    context_window_compression=types.ContextWindowCompressionConfig(
                        trigger_tokens=25600,
                        sliding_window=types.SlidingWindow(target_tokens=12800),
                    ),
                    # üîß System Prompt –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                    system_instruction=self.base_system_instruction,
                    # üîß –í–û–°–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú Google Search
                    tools=[
                        types.Tool(
                            google_search=types.GoogleSearch()
                        )
                    ]
                )
                
                logger.info("‚úÖ Google Search tool configured in Live API")
                
                # –ú–æ–¥–µ–ª—å Live API
                self.live_model = "models/gemini-2.5-flash-live-preview"
                
                # –§–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Live API
                self.use_live_api = True
                
                logger.info("‚úÖ Gemini Live API initialized successfully")
                
            else:
                logger.warning("‚ö†Ô∏è Gemini Live API not available")
                self.live_client = None
                self.live_config = None
                self.live_model = None
                self.use_live_api = False
            
            # üîÑ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LANGCHAIN (fallback)
            if LANGCHAIN_AVAILABLE:
                logger.info("üîÑ Initializing LangChain (fallback)")
                
                self.llm = ChatGoogleGenerativeAI(
                    model="gemini-2.5-flash-lite",
                    google_api_key=Config.GEMINI_API_KEY,
                    temperature=0.7,
                    max_output_tokens=2048
                )
                
                logger.info("‚úÖ LangChain initialized successfully (fallback)")
                
            else:
                logger.warning("‚ö†Ô∏è LangChain not available")
                self.llm = None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω API –¥–æ—Å—Ç—É–ø–µ–Ω
            if not self.use_live_api and not self.llm:
                raise RuntimeError("No LLM API available. Both Live API and LangChain failed to initialize.")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MemoryAnalyzer (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            gemini_api_key = Config.GEMINI_API_KEY
            if gemini_api_key:
                try:
                    from memory_analyzer import MemoryAnalyzer
                    self.memory_analyzer = MemoryAnalyzer(gemini_api_key)
                    logger.info(f"‚úÖ MemoryAnalyzer initialized")
                except ImportError as e:
                    logger.warning(f"‚ö†Ô∏è MemoryAnalyzer cannot be imported: {e}")
                    self.memory_analyzer = None
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è MemoryAnalyzer not initialized: {e}")
                    self.memory_analyzer = None
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing TextProcessor: {e}", exc_info=True)
            self.live_client = None
            self.llm = None
            raise
    

    
    def cancel_generation(self):
        """
        –ú–ì–ù–û–í–ï–ù–ù–û –æ—Ç–º–µ–Ω—è–µ—Ç —Ç–µ–∫—É—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é LLM –∏ –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è.
        """
        try:
            logger.warning("üö® IMMEDIATELY canceling LLM generation!")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –æ—Ç–º–µ–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é Gemini
            if hasattr(self, '_current_generation'):
                try:
                    if hasattr(self._current_generation, 'cancel'):
                        self._current_generation.cancel()
                        logger.warning("üö® Gemini generation IMMEDIATELY CANCELLED!")
                except:
                    pass
                self._current_generation = None
            
            # –ö–†–ò–¢–ò–ß–ù–û: –æ—á–∏—â–∞–µ–º –≤—Å–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –±—É—Ñ–µ—Ä—ã
            if hasattr(self, '_text_buffer'):
                self._text_buffer.clear()
                logger.warning("üö® Text buffers IMMEDIATELY CLEARED!")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –æ—á–∏—â–∞–µ–º –≤—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            if hasattr(self, '_current_prompt'):
                self._current_prompt = None
                logger.warning("üö® Current prompt IMMEDIATELY CLEARED!")
            
            logger.warning("‚úÖ All LLM processes IMMEDIATELY cancelled!")
            
        except Exception as e:
            logger.error(f"‚ùå Error canceling LLM generation: {e}")
    
    def clear_buffers(self):
        """
        –ú–ì–ù–û–í–ï–ù–ù–û –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –±—É—Ñ–µ—Ä—ã –∏ –æ—Ç–º–µ–Ω—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.
        """
        self.cancel_generation()

    def set_database_manager(self, db_manager):
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç DatabaseManager –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞–º—è—Ç—å—é.
        
        Args:
            db_manager: –≠–∫–∑–µ–º–ø–ª—è—Ä DatabaseManager
        """
        self.db_manager = db_manager
        logger.info("‚úÖ DatabaseManager set in TextProcessor")
    
    async def generate_response_stream(self, prompt: str, hardware_id: str = None, screenshot_base64: str = None, interrupt_checker=None, **kwargs) -> AsyncGenerator[str, None]:
        """
        üéØ –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î: –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–¥—É—Ç —á–µ—Ä–µ–∑ Gemini Live API —Å fallback –Ω–∞ LangChain
        """
        try:
            logger.info(f"üöÄ Starting hybrid request processing: '{prompt[:100]}...'")
            
            # üîç –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –í–•–û–î–ù–´–• –î–ê–ù–ù–´–•
            logger.info(f"üñºÔ∏è Hybrid: Input screenshot_base64: {screenshot_base64[:100] if screenshot_base64 else 'None'}...")
            logger.info(f"üñºÔ∏è Hybrid: Input screenshot_base64 length: {len(screenshot_base64) if screenshot_base64 else 0}")
            logger.info(f"üñºÔ∏è Hybrid: Input hardware_id: {hardware_id}")
            
            # üîß –ü–û–õ–£–ß–ê–ï–ú –ö–û–ù–¢–ï–ö–°–¢ –ü–ê–ú–Ø–¢–ò (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            memory_context = ""
            if hardware_id and self.db_manager:
                try:
                    # –¢–∞–π–º–∞—É—Ç 2 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
                    async with asyncio.timeout(2.0):
                        memory_data = await asyncio.to_thread(
                            self.db_manager.get_user_memory, 
                            hardware_id
                        )
                        if memory_data.get('short') or memory_data.get('long'):
                            memory_context = f"""
üß† MEMORY CONTEXT (for response context):

üìã SHORT-TERM MEMORY (current session):
{memory_data.get('short', 'No short-term memory')}

üìö LONG-TERM MEMORY (user information):
{memory_data.get('long', 'No long-term memory')}

üí° MEMORY USAGE INSTRUCTIONS:
- Use short-term memory to understand current conversation context
- Use long-term memory for response personalization (name, preferences, important details)
- If memory is not relevant to current request - ignore it
- Memory should complement the answer, not replace it
- Priority: current request > short-term memory > long-term memory
                            """
                            logger.info(f"üß† Memory obtained for {hardware_id}: short-term ({len(memory_data.get('short', ''))} chars), long-term ({len(memory_data.get('long', ''))} chars)")
                        else:
                            logger.info(f"üß† Memory for {hardware_id} is empty")
                except asyncio.TimeoutError:
                    logger.warning(f"‚è∞ Timeout getting memory for {hardware_id}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error getting memory: {e}")
            
            # üîß –§–û–†–ú–ò–†–£–ï–ú –ö–û–ù–¢–ï–ù–¢ –î–õ–Ø –ó–ê–ü–†–û–°–ê —Å –ø–∞–º—è—Ç—å—é
            user_content = prompt
            if memory_context:
                user_content = f"Memory context: {memory_context}\n\n User command: {prompt}"
                logger.info(f"üß† User content prepared with memory: {len(user_content)} chars")
            else:
                logger.info(f"üìù User content without memory: {len(user_content)} chars")
            
            # üîß –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: —Å–∫—Ä–∏–Ω—à–æ—Ç —É–∂–µ Base64 —Å—Ç—Ä–æ–∫–∞
            screenshot_data = None
            if screenshot_base64:
                logger.info("üñºÔ∏è Hybrid: Screenshot Base64 received directly")
                logger.info(f"üñºÔ∏è Hybrid: Base64 validation:")
                logger.info(f"   - Base64 length: {len(screenshot_base64)} chars")
                logger.info(f"   - Base64 starts with: {screenshot_base64[:50]}...")
                logger.info(f"   - Base64 ends with: ...{screenshot_base64[-20:]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å Base64
                if len(screenshot_base64) < 100:
                    logger.warning("‚ö†Ô∏è Hybrid: Base64 string seems too short!")
                if not screenshot_base64.replace('+', '').replace('/', '').replace('=', '').isalnum():
                    logger.warning("‚ö†Ô∏è Hybrid: Base64 string may be corrupted!")
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è LangChain
                screenshot_data = {
                    "mime_type": "image/jpeg",  # JPEG –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
                    "data": screenshot_base64,
                    "raw_bytes": None,  # –ù–µ –Ω—É–∂–Ω—ã
                    "width": 0,
                    "height": 0,
                    "size_bytes": len(screenshot_base64)
                }
                logger.info(f"üñºÔ∏è Hybrid: Screenshot data prepared:")
                logger.info(f"   - MIME type: {screenshot_data['mime_type']}")
                logger.info(f"   - Base64 data: {len(screenshot_data['data'])} chars")
            else:
                logger.info("üñºÔ∏è Hybrid: No screenshot_base64 provided")
            
            # üöÄ –ü–†–ò–û–†–ò–¢–ï–¢ 1: –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏–¥—É—Ç —á–µ—Ä–µ–∑ Gemini Live API (—Ç–µ–∫—Å—Ç + –∞—É–¥–∏–æ)
            if self.use_live_api and self.live_client:
                try:
                    logger.info("üöÄ Main: Using Gemini Live API for ALL requests (text + audio generation)")
                    
                    # üöÄ –ò–°–ü–û–õ–¨–ó–£–ï–ú Gemini Live API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –∞—É–¥–∏–æ
                    async for chunk in self._call_live_api_directly(
                        user_content, hardware_id, screenshot_data, interrupt_checker, **kwargs
                    ):
                        yield chunk
                    return  # –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∏ —Å Live API
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Main: Live API failed, falling back to LangChain (TEXT ONLY): {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ fallback –¢–û–õ–¨–ö–û –ø—Ä–∏ –æ—à–∏–±–∫–µ Live API
                    pass
            else:
                logger.info("üîÑ Main: Live API not available, using LangChain fallback (TEXT ONLY)...")
            
            # üîÑ FALLBACK: –ò—Å–ø–æ–ª—å–∑—É–µ–º LangChain –¢–û–õ–¨–ö–û –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ –∞—É–¥–∏–æ)
            if self.llm:
                logger.info("üîÑ Main: Using LangChain fallback (TEXT ONLY - no audio generation)...")
                try:
                    # üîß –ü–û–î–î–ï–†–ñ–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –í FALLBACK
                    if screenshot_base64:
                        logger.info("üñºÔ∏è Main: LangChain fallback - Screenshot detected")
                        
                        # –°–æ–∑–¥–∞–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
                        messages = [
                            SystemMessage(content=self.base_system_instruction),
                            HumanMessage(content=[
                                {
                                    "type": "text",
                                    "text": user_content  # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: user_content –≤–º–µ—Å—Ç–æ prompt
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{screenshot_base64}"  # üîß JPEG –≤–º–µ—Å—Ç–æ WebP
                                    }
                                }
                            ])
                        ]
                        logger.info("‚úÖ Main: LangChain fallback - Multimodal message created")
                    else:
                        # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                        messages = [
                            SystemMessage(content=self.base_system_instruction),
                            HumanMessage(content=user_content)  # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: user_content –≤–º–µ—Å—Ç–æ prompt
                        ]
                        logger.info("‚úÖ Main: LangChain fallback - Text-only message created")
                    
                    # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ LLM —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º
                    buffer = ""  # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
                    full_response = ""  # –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞–º—è—Ç–∏
                    
                    async for chunk in self.llm.astream(messages, config={
                        "cache": False,
                        "force_refresh": True
                    }):
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —á–∞–Ω–∫–∞
                        if hasattr(chunk, 'content'):
                            content = chunk.content
                        elif hasattr(chunk, 'text'):
                            content = chunk.text
                        else:
                            content = str(chunk)
                        
                        # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ –∏ –ø–æ–ª–Ω–æ–º –æ—Ç–≤–µ—Ç–µ
                        if content:
                            buffer += content
                            full_response += content
                            
                            # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ª–æ–≥–∏–∫–∞ —Å—Ç—Ä–∏–º–º–∏–Ω–≥–∞ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (LangChain)
                            sentences = self._split_into_sentences(buffer)
                            
                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
                            if len(sentences) >= 1:
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                                for sentence in sentences[:-1]:
                                    if sentence.strip():
                                        # üîÑ LANGCHAIN FALLBACK: –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä "TEXT_ONLY" –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∞—É–¥–∏–æ
                                        yield f"__LANGCHAIN_TEXT_ONLY__:{sentence.strip()}"
                                
                                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏ –æ–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ
                                if len(sentences) == 1 and is_sentence_complete(sentences[0]):
                                    # üîÑ LANGCHAIN FALLBACK: –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä "TEXT_ONLY" –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∞—É–¥–∏–æ
                                    yield f"__LANGCHAIN_TEXT_ONLY__:{sentences[0].strip()}"
                                    buffer = ""  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                                else:
                                    # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ
                                    buffer = sentences[-1]
                            
                            # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –º–µ—Ä–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è
                            # –ï—Å–ª–∏ –±—É—Ñ–µ—Ä —Å—Ç–∞–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º (>200 —Å–∏–º–≤–æ–ª–æ–≤), –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º
                            if len(buffer) > 200:
                                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –±—É—Ñ–µ—Ä
                                forced_sentences = self._split_into_sentences(buffer)
                                if len(forced_sentences) > 1:
                                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                                    for sentence in forced_sentences[:-1]:
                                        if sentence.strip():
                                            # üîÑ LANGCHAIN FALLBACK: –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä "TEXT_ONLY" –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∞—É–¥–∏–æ
                                            yield f"__LANGCHAIN_TEXT_ONLY__:{sentence.strip()}"
                                    buffer = forced_sentences[-1]
                                elif len(forced_sentences) == 1 and is_sentence_complete(forced_sentences[0]):
                                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                                    # üîÑ LANGCHAIN FALLBACK: –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä "TEXT_ONLY" –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∞—É–¥–∏–æ
                                    yield f"__LANGCHAIN_TEXT_ONLY__:{forced_sentences[0].strip()}"
                                    buffer = ""
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –≤ –±—É—Ñ–µ—Ä–µ
                    if buffer.strip():
                        # üîÑ LANGCHAIN FALLBACK: –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä "TEXT_ONLY" –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∞—É–¥–∏–æ
                        yield f"__LANGCHAIN_TEXT_ONLY__:{buffer.strip()}"
                        full_response += buffer.strip()
                    
                    logger.info("‚úÖ Main: LangChain fallback - Streaming completed successfully")
                    
                    # –§–û–ù–û–í–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Å –†–ï–ê–õ–¨–ù–´–ú –æ—Ç–≤–µ—Ç–æ–º
                    if hardware_id and self.db_manager and self.memory_analyzer:
                        asyncio.create_task(
                            self._update_memory_background(hardware_id, user_content, full_response)
                        )
                        logger.info(f"üîÑ Main: Memory update task started in background for {hardware_id} with real response ({len(full_response)} chars)")
                    
                except Exception as e:
                    logger.error(f"‚ùå Main: LangChain fallback also failed: {e}")
                    yield f"Sorry, both Live API and LangChain failed. Error: {e}"
            else:
                logger.error("‚ùå Main: No LLM API available")
                yield "Sorry, no AI service is currently available."
                
        except Exception as e:
            logger.error(f"‚ùå Main: Error in main request processing: {e}", exc_info=True)
            yield "Sorry, an internal error occurred while processing your request."
    
    # clean_text method removed - using common utility function

    def _split_into_sentences(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É"""
        return split_into_sentences(text)
    
    # _is_sentence_complete method removed - using common utility function
    
    async def _call_live_api_directly(self, user_content: str, hardware_id: str = None, screenshot_data: dict = None, interrupt_checker=None, **kwargs) -> AsyncGenerator[str, None]:
        """
        üöÄ –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ Gemini Live API —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        try:
            logger.info(f"üöÄ Live API Direct: Starting request: '{user_content[:100]}...'")
            logger.info(f"üîç Live API Direct: Full user_content: '{user_content}'")
            logger.info(f"üîç Live API Direct: Content length: {len(user_content)} characters")
            
            # üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–µ—Ä–µ–¥ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º
            logger.info(f"üîç Live API Direct: Configuration check:")
            logger.info(f"   - Model: {self.live_model}")
            logger.info(f"   - API Key: {Config.GEMINI_API_KEY[:10] if Config.GEMINI_API_KEY else 'None'}...")
            logger.info(f"   - Tools configured: {len(self.live_config.tools) if hasattr(self.live_config, 'tools') else 0}")
            if hasattr(self.live_config, 'tools') and self.live_config.tools:
                for i, tool in enumerate(self.live_config.tools):
                    if hasattr(tool, 'google_search'):
                        logger.info(f"   - Tool {i+1}: Google Search ‚úÖ")
                    else:
                        logger.info(f"   - Tool {i+1}: {type(tool).__name__}")
            logger.info(f"   - Config: {self.live_config}")
            
            # –°–æ–∑–¥–∞–µ–º Live API —Å–µ—Å—Å–∏—é
            async with self.live_client.aio.live.connect(model=self.live_model, config=self.live_config) as session:
                try:
                    # üîß System Prompt —É–∂–µ –ø–µ—Ä–µ–¥–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ - –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    logger.info("üöÄ Live API Direct: System Prompt already in config - no need to send as system message")
                    
                    # üîß –û–ë–†–ê–ë–û–¢–ö–ê –°–ö–†–ò–ù–®–û–¢–û–í (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    parts = []
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å
                    parts.append(types.Part.from_text(text=user_content))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
                    if screenshot_data and screenshot_data.get('data'):
                        try:
                            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º Base64 –¥–∞–Ω–Ω—ã–µ
                            import base64
                            image_data = base64.b64decode(screenshot_data['data'])
                            
                            # –°–æ–∑–¥–∞–µ–º Part —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
                            image_part = types.Part.from_bytes(
                                data=image_data,
                                mime_type=screenshot_data.get('mime_type', 'image/jpeg')
                            )
                            parts.append(image_part)
                            
                            logger.info(f"üñºÔ∏è Live API Direct: Screenshot added - {len(image_data)} bytes, MIME: {screenshot_data.get('mime_type', 'image/jpeg')}")
                            
                        except Exception as e:
                            logger.error(f"‚ùå Live API Direct: Error processing screenshot: {e}")
                            logger.warning("‚ö†Ô∏è Live API Direct: Continuing with text-only mode")
                    
                    logger.info(f"üîç Live API Direct: Sending content with {len(parts)} parts: '{user_content[:100]}...'")
                    
                    # üîß –û–¢–ü–†–ê–í–õ–Ø–ï–ú –ö–û–ù–¢–ï–ù–¢ (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å)
                    if len(parts) == 1:
                        # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                        await session.send(input=user_content, end_of_turn=True)
                    else:
                        # –¢–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º send_client_content
                        await session.send_client_content(
                            turns=types.Content(
                                role='user',
                                parts=parts
                            ),
                            turn_complete=True
                        )
                    
                    if len(parts) == 1:
                        logger.info("‚úÖ Live API Direct: Text-only message sent successfully")
                    else:
                        logger.info(f"‚úÖ Live API Direct: Multimodal message sent successfully ({len(parts)} parts)")
                    
                    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
                    buffer = ""  # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
                    full_response = ""  # –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞–º—è—Ç–∏
                    
                    turn = session.receive()
                    async for response in turn:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                        if hasattr(response, 'text') and response.text:
                            content = response.text
                            
                            # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ –∏ –ø–æ–ª–Ω–æ–º –æ—Ç–≤–µ—Ç–µ
                            if content:
                                buffer += content
                                full_response += content
                                
                                # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ª–æ–≥–∏–∫–∞ —Å—Ç—Ä–∏–º–º–∏–Ω–≥–∞ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                                sentences = self._split_into_sentences(buffer)
                                
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
                                if len(sentences) >= 1:
                                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                                    for sentence in sentences[:-1]:
                                        if sentence.strip():
                                            yield sentence.strip()
                                    
                                    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏ –æ–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–≥–æ
                                    if len(sentences) == 1 and is_sentence_complete(sentences[0]):
                                        yield sentences[0].strip()
                                        buffer = ""  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                                    else:
                                        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ
                                        buffer = sentences[-1]
                                
                                # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –º–µ—Ä–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è
                                # –ï—Å–ª–∏ –±—É—Ñ–µ—Ä —Å—Ç–∞–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º (>200 —Å–∏–º–≤–æ–ª–æ–≤), –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º
                                if len(buffer) > 200:
                                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –±—É—Ñ–µ—Ä
                                    forced_sentences = self._split_into_sentences(buffer)
                                    if len(forced_sentences) > 1:
                                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                                        for sentence in forced_sentences[:-1]:
                                            if sentence.strip():
                                                yield sentence.strip()
                                        buffer = forced_sentences[-1]
                                    elif len(forced_sentences) == 1 and is_sentence_complete(forced_sentences[0]):
                                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                                        yield forced_sentences[0].strip()
                                        buffer = ""
                        
                        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ tool calls
                        if hasattr(response, 'tool_calls') and response.tool_calls:
                            for tool_call in response.tool_calls:
                                logger.info(f"üîç Live API Direct: Tool call detected: {tool_call.function.name}")
                                if hasattr(tool_call, 'function') and tool_call.function.name == 'google_search':
                                    logger.info(f"üîç Live API Direct: Google Search tool call detected!")
                                    # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ Live API
                                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∏–¥—É—Ç –≤ —Å–ª–µ–¥—É—é—â–∏—Ö response
                        
                        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ tool calls
                        if hasattr(response, 'tool_response') and response.tool_response:
                            logger.info(f"üîç Live API Direct: Tool response received!")
                            logger.info(f"üîç Live API Direct: Tool response type: {type(response.tool_response).__name__}")
                            logger.info(f"üîç Live API Direct: Tool response attributes: {dir(response.tool_response)}")
                            
                            if hasattr(response.tool_response, 'google_search'):
                                logger.info(f"üîç Live API Direct: Google Search results received!")
                                # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞—é—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                            else:
                                logger.info(f"üîç Live API Direct: Other tool response: {type(response.tool_response).__name__}")
                        
                        # üîß –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º parts –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
                        if hasattr(response, 'parts') and response.parts:
                            for i, part in enumerate(response.parts):
                                if hasattr(part, 'text') and part.text:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
                                    text_lower = part.text.lower()
                                    if any(keyword in text_lower for keyword in ['search results', 'google search', 'found information', 'according to']):
                                        logger.info(f"üîç Live API Direct: Part {i} contains search results!")
                                elif hasattr(part, 'google_search'):
                                    logger.info(f"üîç Live API Direct: Part {i} contains Google Search data!")
                            
                            # üö´ –§–ò–õ–¨–¢–†–£–ï–ú executable_code - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–¥–∞
                            for part in response.parts:
                                if hasattr(part, 'executable_code') and part.executable_code:
                                    logger.info(f"üö´ Live API Direct: Executable code detected and IGNORED (we don't need code generation)")
                                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–¥ - –Ω–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                                
                                if hasattr(part, 'code_execution_result') and part.code_execution_result:
                                    logger.info(f"üö´ Live API Direct: Code execution result detected and IGNORED (we don't need code execution)")
                                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–¥–∞
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –≤ –±—É—Ñ–µ—Ä–µ
                    if buffer.strip():
                        yield buffer.strip()
                        full_response += buffer.strip()
                    
                    logger.info("‚úÖ Live API Direct: Streaming completed successfully")
                    
                    # –§–û–ù–û–í–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Å –†–ï–ê–õ–¨–ù–´–ú –æ—Ç–≤–µ—Ç–æ–º
                    if hardware_id and self.db_manager and self.memory_analyzer:
                        asyncio.create_task(
                            self._update_memory_background(hardware_id, user_content, full_response)
                        )
                        logger.info(f"üîÑ Live API Direct: Memory update task started in background for {hardware_id} with real response ({len(full_response)} chars)")
                    
                except Exception as e:
                    logger.error(f"‚ùå Live API Direct: Error in session: {e}")
                    raise
                    
        except Exception as e:
            logger.error(f"‚ùå Live API Direct: Error in request processing: {e}", exc_info=True)
            yield f"Sorry, an error occurred while processing your request with Live API: {e}"

    async def _update_memory_background(self, hardware_id: str, prompt: str, response: str):
        """
        –§–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            hardware_id: –ê–ø–ø–∞—Ä–∞—Ç–Ω—ã–π ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        """
        try:
            logger.debug(f"üîÑ Starting background memory update for {hardware_id}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
            short_memory, long_memory = await self.memory_analyzer.analyze_conversation(
                prompt, 
                response
            )
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
            if short_memory or long_memory:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–º—è—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                success = await asyncio.to_thread(
                    self.db_manager.update_user_memory,
                    hardware_id,
                    short_memory,
                    long_memory
                )
                
                if success:
                    logger.info(f"‚úÖ Memory for {hardware_id} updated: short-term ({len(short_memory)} chars), long-term ({len(long_memory)} chars)")
                else:
                    logger.warning(f"‚ö†Ô∏è Could not update memory for {hardware_id}")
            else:
                logger.debug(f"üß† No information found for {hardware_id} to remember")
                
        except Exception as e:
            logger.error(f"‚ùå Error in background memory update for {hardware_id}: {e}")
            # –ù–ï –ø–æ–¥–Ω–∏–º–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ - —ç—Ç–æ —Ñ–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞