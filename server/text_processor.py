import asyncio
import logging
import os
import re
from typing import AsyncGenerator, List

# üö® –ó–ê–ú–ï–ù–ê: Gemini Live API ‚Üí LangChain + Google Gemini
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_core.messages import HumanMessage, SystemMessage
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    LANGCHAIN_AVAILABLE = False

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ---
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–ª—é—á–µ–π API
if not os.environ.get("GEMINI_API_KEY"):
    raise ValueError("GEMINI_API_KEY not found. Check config.env")

logger = logging.getLogger(__name__)

# –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –∏–º–ø–æ—Ä—Ç–∞ LangChain
if LANGCHAIN_AVAILABLE:
    logger.info("‚úÖ LangChain + Google Gemini imported successfully")
else:
    logger.warning(f"‚ö†Ô∏è LangChain unavailable: {e}")

class TextProcessor:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Google Gemini —á–µ—Ä–µ–∑ LangChain,
    –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, Google Search)
    –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç—Ä–∏–º–∏–Ω–≥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
    
    üö® –í–ê–ñ–ù–û: System Prompt —Ç–µ–ø–µ—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏,
    –∞ –Ω–µ –∫–∞–∫ –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
    """
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–º—è—Ç–∏
        self.memory_analyzer = None
        self.db_manager = None
        
        # ‚úÖ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ü–†–û–°–¢–û–ô System Prompt (—Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        self.base_system_instruction = (
            "You are a helpful assistant for blind and visually impaired users. "
            "Answer on question, exactly what user wants to know or get. Don't mix  answers of conversations or describe screenshot.\n"
   
            
            "üéØ YOUR CAPABILITIES:\n\n"
            
            "üí¨ BASIC CONVERSATION - for:\n"
            "- General questions and explanations\n"
            "- How things work\n"
            "- Definitions and concepts\n"
            "- Historical facts\n"
            "- Scientific explanations\n"
            "- Simple advice and help\n\n"
            
            "üì± SCREEN ANALYSIS - if screenshot available:\n"
            "- Use screenshot ONLY as visual context for your response\n"
            "- DO NOT return JSON coordinates or technical image analysis\n"
            "- Simply describe what you see on screen in natural language\n"
            "- Focus on helping the user with their question\n"
            "- If you see any dangerous content, warn about it\n\n"
            
            "üìã RESPONSE RULES:\n"
            "- Answer briefly and clearly\n"
            "- Be friendly and helpful\n"
            "- Don't over-explain\n"
            "- Focus on what the user needs\n"
            
            
            
            
            "REMEMBER: Keep it simple, helpful, Use memory just in case if you need to use, it's really helpful but otherwise don't use it, also Screenshot if user don't ask you to describe or talk about you don't need to talk about this if user ask you about a screenshot then in this case, you need to talk about screenshot and describe it!"
        )
        
        logger.info(f"‚úÖ base_system_instruction created: {len(self.base_system_instruction)} characters")
        
        try:
            # ‚úÖ –£–ü–†–û–©–ï–ù–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø (–∫–∞–∫ –≤ langchain_test)
            if LANGCHAIN_AVAILABLE:
                logger.info("‚úÖ Using LangChain + Google Gemini (simplified version)")
                
                # ‚úÖ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LangChain
                self.use_langchain = True
                
                # ‚úÖ –ü–†–û–°–¢–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø LangChain –ë–ï–ó –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ
                self.llm = ChatGoogleGenerativeAI(
                    model="gemini-2.5-flash-lite",
                    google_api_key=os.environ.get("GEMINI_API_KEY"),
                    temperature=0.7,
                    max_output_tokens=2048,
                    streaming=True,  # üîß –í–ö–õ–Æ–ß–ê–ï–ú –°–¢–†–ò–ú–ò–ù–ì!
                    cache=False,
                    # üîß –û–¢–ö–õ–Æ–ß–ê–ï–ú –ö–≠–®–ò–†–û–í–ê–ù–ò–ï –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–µ–∂–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    force_refresh=True
                )
                
                # ‚úÖ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ü–†–û–°–¢–ê–Ø –°–ò–°–¢–ï–ú–ê (—Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
                logger.info("‚úÖ System simplified - no tools, only basic conversation")
                
                logger.info(f"‚úÖ TextProcessor with LangChain initialized successfully")
                
            else:
                # ‚ùå LangChain –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
                logger.error("‚ùå CRITICAL ERROR: LangChain unavailable!")
                raise ImportError("LangChain unavailable. Install required dependencies.")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MemoryAnalyzer (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            gemini_api_key = os.environ.get("GEMINI_API_KEY")
            if gemini_api_key:
                try:
                    from memory_analyzer import MemoryAnalyzer
                    self.memory_analyzer = MemoryAnalyzer(gemini_api_key)
                    logger.info(f"‚úÖ MemoryAnalyzer initialized")
                except ImportError as e:
                    logger.warning(f"‚ö†Ô∏è MemoryAnalyzer cannot be imported: {e}")
                    self.memory_analyzer = None
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è MemoryAnalyzer not initialized: {e}")
                    self.memory_analyzer = None
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing TextProcessor: {e}", exc_info=True)
            self.llm = None
    

    
    def cancel_generation(self):
        """
        –ú–ì–ù–û–í–ï–ù–ù–û –æ—Ç–º–µ–Ω—è–µ—Ç —Ç–µ–∫—É—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é LLM –∏ –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è.
        """
        try:
            logger.warning("üö® IMMEDIATELY canceling LLM generation!")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –æ—Ç–º–µ–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é Gemini
            if hasattr(self, '_current_generation'):
                try:
                    if hasattr(self._current_generation, 'cancel'):
                        self._current_generation.cancel()
                        logger.warning("üö® Gemini generation IMMEDIATELY CANCELLED!")
                except:
                    pass
                self._current_generation = None
            
            # –ö–†–ò–¢–ò–ß–ù–û: –æ—á–∏—â–∞–µ–º –≤—Å–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –±—É—Ñ–µ—Ä—ã
            if hasattr(self, '_text_buffer'):
                self._text_buffer.clear()
                logger.warning("üö® Text buffers IMMEDIATELY CLEARED!")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –æ—á–∏—â–∞–µ–º –≤—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            if hasattr(self, '_current_prompt'):
                self._current_prompt = None
                logger.warning("ÔøΩÔøΩ Current prompt IMMEDIATELY CLEARED!")
            
            logger.warning("‚úÖ All LLM processes IMMEDIATELY cancelled!")
            
        except Exception as e:
            logger.error(f"‚ùå Error canceling LLM generation: {e}")
    
    def clear_buffers(self):
        """
        –ú–ì–ù–û–í–ï–ù–ù–û –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –±—É—Ñ–µ—Ä—ã –∏ –æ—Ç–º–µ–Ω—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.
        """
        self.cancel_generation()

    def set_database_manager(self, db_manager):
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç DatabaseManager –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞–º—è—Ç—å—é.
        
        Args:
            db_manager: –≠–∫–∑–µ–º–ø–ª—è—Ä DatabaseManager
        """
        self.db_manager = db_manager
        logger.info("‚úÖ DatabaseManager set in TextProcessor")
    
    async def generate_response_stream(self, prompt: str, hardware_id: str = None, screenshot_base64: str = None, interrupt_checker=None, **kwargs) -> AsyncGenerator[str, None]:
        """
        üéØ –£–ü–†–û–©–ï–ù–ù–´–ô –ú–ï–¢–û–î: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LangChain (–∫–∞–∫ –≤ langchain_test)
        """
        try:
            logger.info(f"üöÄ Starting request processing: '{prompt[:100]}...'")
            
            # –ö–†–ò–¢–ò–ß–ù–û: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
            self._interrupt_checker = interrupt_checker
            self._current_prompt = prompt
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            memory_context = ""
            if hardware_id and self.db_manager:
                try:
                    # –¢–∞–π–º–∞—É—Ç 2 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
                    async with asyncio.timeout(2.0):
                        memory_data = await asyncio.to_thread(
                            self.db_manager.get_user_memory, 
                            hardware_id
                        )
                        if memory_data.get('short') or memory_data.get('long'):
                            memory_context = f"""
üß† MEMORY CONTEXT (for response context):

üìã SHORT-TERM MEMORY (current session):
{memory_data.get('short', 'No short-term memory')}

üìö LONG-TERM MEMORY (user information):
{memory_data.get('long', 'No long-term memory')}

üí° MEMORY USAGE INSTRUCTIONS:
- Use short-term memory to understand current conversation context
- Use long-term memory for response personalization (name, preferences, important details)
- If memory is not relevant to current request - ignore it
- Memory should complement the answer, not replace it
- Priority: current request > short-term memory > long-term memory
                            """
                            logger.info(f"üß† Memory obtained for {hardware_id}: short-term ({len(memory_data.get('short', ''))} chars), long-term ({len(memory_data.get('long', ''))} chars)")
                        else:
                            logger.info(f"üß† Memory for {hardware_id} is empty")
                except asyncio.TimeoutError:
                    logger.warning(f"‚è∞ Timeout getting memory for {hardware_id}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error getting memory: {e}")
            
            # üö® –£–ü–†–û–©–ï–ù–ù–´–ô –ü–û–î–•–û–î: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ LLM
            logger.info("üöÄ Using direct LLM call (no chain)")
                
            # üîß –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            user_content = prompt
            if memory_context:
                user_content = f"{memory_context}\n\n{prompt}"
            
            # üö® –£–ë–†–ê–ù–û: –¥—É–±–ª–∏—Ä—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ —è–∑—ã–∫–∞ - —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ base_system_instruction
                
            # üîß –ü–†–Ø–ú–û–ô –í–´–ó–û–í LLM –±–µ–∑ —Ü–µ–ø–æ—á–∫–∏
            try:
                # üîß –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–π —Ç–µ–∫—Å—Ç - —Å—Ä–∞–∑—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
                async with asyncio.timeout(15.0):  # 15 —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø—Ä–æ—Å—Ç—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                    
                    # üîß –ü–û–î–î–ï–†–ñ–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô: —Å–æ–∑–¥–∞–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    if screenshot_base64:
                        logger.info("üñºÔ∏è Screenshot detected - creating multimodal request")
                        
                        # –°–æ–∑–¥–∞–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
                        # üîß System Prompt –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –∞ –Ω–µ –∫–∞–∫ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        messages = [
                            SystemMessage(content=self.base_system_instruction),
                            HumanMessage(content=[
                                {
                                    "type": "text",
                                    "text": user_content
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/webp;base64,{screenshot_base64}"
                                    }
                                }
                            ])
                        ]
                        logger.info("‚úÖ Multimodal message created with WebP image")
                    else:
                        # –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
                        # ‚úÖ System Prompt –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∫–∞–∫ SystemMessage –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π
                        messages = [
                            SystemMessage(content=self.base_system_instruction),
                            HumanMessage(content=user_content)
                        ]
                        logger.info("‚úÖ Text-only message created")
                    
                    # üîß –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ LLM —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º
                    buffer = ""  # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
                    full_response = ""  # üîß –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞–º—è—Ç–∏
                    
                    async for chunk in self.llm.astream(messages, config={
                        "cache": False,
                        "force_refresh": True
                    }):
                        # üîß –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —á–∞–Ω–∫–∞
                        if hasattr(chunk, 'content'):
                            content = chunk.content
                        elif hasattr(chunk, 'text'):
                            content = chunk.text
                        else:
                            content = str(chunk)
                        
                        # üîß –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ –∏ –ø–æ–ª–Ω–æ–º –æ—Ç–≤–µ—Ç–µ
                        if content:
                            buffer += content
                            full_response += content  # üîß –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–∞–º—è—Ç–∏
                            
                            # üîß –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                            sentences = self._split_into_sentences(buffer)
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö
                            if len(sentences) > 1:
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ (–æ–Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º)
                                for sentence in sentences[:-1]:
                                    if sentence.strip():
                                        yield sentence.strip()
                                
                                # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ
                                buffer = sentences[-1]
                    
                    # üîß –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –≤ –±—É—Ñ–µ—Ä–µ
                    if buffer.strip():
                        yield buffer.strip()
                        full_response += buffer.strip()  # üîß –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                    
                    logger.info("‚úÖ Direct LLM streaming completed successfully")
                    
                    # üîß –§–û–ù–û–í–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ —Å –†–ï–ê–õ–¨–ù–´–ú –æ—Ç–≤–µ—Ç–æ–º
                    if hardware_id and self.db_manager and self.memory_analyzer:
                        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –≤ —Ñ–æ–Ω–µ —Å –†–ï–ê–õ–¨–ù–´–ú –æ—Ç–≤–µ—Ç–æ–º
                        asyncio.create_task(
                            self._update_memory_background(hardware_id, prompt, full_response)
                        )
                        logger.info(f"üîÑ Memory update task started in background for {hardware_id} with real response ({len(full_response)} chars)")
                    elif hardware_id and self.db_manager:
                        logger.warning(f"‚ö†Ô∏è MemoryAnalyzer unavailable for {hardware_id}, memory will not be updated")
                    elif hardware_id:
                        logger.warning(f"‚ö†Ô∏è DatabaseManager unavailable for {hardware_id}, memory will not be updated")
                    
            except asyncio.TimeoutError:
                logger.warning("‚è∞ Timeout - using fallback")
                # Fallback: —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º
                
                # üîß –ü–û–î–î–ï–†–ñ–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –í FALLBACK
                if screenshot_base64:
                    logger.info("üñºÔ∏è Screenshot detected in fallback - creating multimodal request")
                    # ‚úÖ System Prompt –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∫–∞–∫ SystemMessage –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π
                    messages = [
                        SystemMessage(content=self.base_system_instruction),
                        HumanMessage(content=[
                            {
                                "type": "text",
                                "text": user_content
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/webp;base64,{screenshot_base64}"
                                }
                            }
                        ])
                    ]
                else:
                    # ‚úÖ System Prompt –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –∫–∞–∫ SystemMessage –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π
                    messages = [
                        SystemMessage(content=self.base_system_instruction),
                        HumanMessage(content=user_content)
                    ]
                
                # üîß Fallback —Å—Ç—Ä–∏–º–∏–Ω–≥ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                buffer = ""  # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
                
                for chunk in self.llm.stream(messages, config={
                    "cache": False,
                    "force_refresh": True
                }):
                    # üîß –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —á–∞–Ω–∫–∞
                    if hasattr(chunk, 'content'):
                        content = chunk.content
                    elif hasattr(chunk, 'text'):
                        content = chunk.text
                    else:
                        content = str(chunk)
                    
                    # üîß –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ
                    if content:
                        buffer += content
                        
                        # üîß –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                        sentences = self._split_into_sentences(buffer)
                        
                        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö
                        if len(sentences) > 1:
                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ (–æ–Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º)
                            for sentence in sentences[:-1]:
                                if sentence.strip():
                                    yield sentence.strip()
                            
                            # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä–µ
                            buffer = sentences[-1]
                
                # üîß –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç –≤ –±—É—Ñ–µ—Ä–µ
                if buffer.strip():
                    yield buffer.strip()
                
                logger.info("‚úÖ Fallback LLM streaming completed successfully")
                    
            except Exception as e:
                logger.error(f"‚ùå Error in direct LLM call: {e}")
                yield f"Sorry, an error occurred while processing your request: {e}"
            
            # üîß –ü–ê–ú–Ø–¢–¨ –û–ë–ù–û–í–õ–Ø–ï–¢–°–Ø –í –û–°–ù–û–í–ù–û–ú –°–¢–†–ò–ú–ï —Å —Ä–µ–∞–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º

        except Exception as e:
            logger.error(f"Error in request processing: {e}", exc_info=True)
            yield "Sorry, an internal error occurred while processing your request."
    
    def clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if not text:
            return ""
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = ' '.join(text.split())
        
        # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –º–µ—à–∞—Ç—å
        text = re.sub(r'[^\w\s\.\,\!\?\-\:\;\(\)\[\]\{\}\"\']', '', text)
        
        return text.strip()

    def _split_into_sentences(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞"""
        if not text:
            return []
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        text = self.clean_text(text)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        
        # üéØ –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–ê–¢–¢–ï–†–ù –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        # –£—á–∏—Ç—ã–≤–∞–µ–º:
        # - –¢–æ—á–∫–∏ (.)
        # - –í–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏ (!)
        # - –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏ (?)
        # - –ú–Ω–æ–≥–æ—Ç–æ—á–∏–µ (...)
        # - –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ (!?, ?!)
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ—á–∫–∏ –≤ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è—Ö (—Ç.–¥., –∏ —Ç.–ø., Dr., Mr., etc.)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentence_pattern = r'(?<=[.!?])\s+(?=[A-Z–ê-–Ø])'
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
        sentences = re.split(sentence_pattern, text)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        result = []
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if sentence:
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                if i < len(sentences) - 1:
                    # –ò—â–µ–º –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ
                    if not any(sentence.endswith(ending) for ending in ['.', '!', '?', '...', '?!', '!?']):
                        sentence += '.'
                result.append(sentence)
        
        return result
    
    async def _smart_stream_content(self, content: str) -> AsyncGenerator[str, None]:
        """–£–º–Ω—ã–π —Å—Ç—Ä–∏–º–∏–Ω–≥ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        if not content or not content.strip():
            return
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = self._split_into_sentences(content)
        
        for sentence in sentences:
            if sentence.strip():
                yield sentence.strip()
    
    def _is_complete_sentence(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–ª–Ω—ã–º"""
        if not text:
            return False
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        text = self.clean_text(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∑–Ω–∞–∫–æ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentence_endings = ['.', '!', '?', '...', '?!', '!?']
        return any(text.endswith(ending) for ending in sentence_endings)
    
    async def _update_memory_background(self, hardware_id: str, prompt: str, response: str):
        """
        –§–æ–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            hardware_id: –ê–ø–ø–∞—Ä–∞—Ç–Ω—ã–π ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        """
        try:
            logger.debug(f"üîÑ Starting background memory update for {hardware_id}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–≥–æ–≤–æ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
            short_memory, long_memory = await self.memory_analyzer.analyze_conversation(
                prompt, 
                response
            )
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
            if short_memory or long_memory:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–º—è—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                success = await asyncio.to_thread(
                    self.db_manager.update_user_memory,
                    hardware_id,
                    short_memory,
                    long_memory
                )
                
                if success:
                    logger.info(f"‚úÖ Memory for {hardware_id} updated: short-term ({len(short_memory)} chars), long-term ({len(long_memory)} chars)")
                else:
                    logger.warning(f"‚ö†Ô∏è Could not update memory for {hardware_id}")
            else:
                logger.debug(f"üß† No information found for {hardware_id} to remember")
                
        except Exception as e:
            logger.error(f"‚ùå Error in background memory update for {hardware_id}: {e}")
            # –ù–ï –ø–æ–¥–Ω–∏–º–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ - —ç—Ç–æ —Ñ–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞