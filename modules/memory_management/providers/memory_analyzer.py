"""
Memory Analyzer - –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:
- –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏ (–∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞)
- –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏ (–≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ)

–≠—Ç–æ—Ç –∫–ª–∞—Å—Å –∑–∞–º–µ–Ω—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π memory_analyzer.py
"""

import asyncio
import logging
import re
from typing import Tuple

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None

logger = logging.getLogger(__name__)

class MemoryAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏.
    """
    
    def __init__(self, gemini_api_key: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MemoryAnalyzer.
        
        Args:
            gemini_api_key: API –∫–ª—é—á –¥–ª—è Gemini
        """
        if not GEMINI_AVAILABLE:
            raise ImportError("google.generativeai not available")
        
        self.api_key = gemini_api_key
        genai.configure(api_key=gemini_api_key)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
        self.model_name = "gemini-2.5-flash-lite"
        self.temperature = 0.3
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞–º—è—Ç–∏
        self.analysis_prompt_template = """
        Analyze this conversation between user and AI assistant to extract memory information.
        
        USER INPUT: {prompt}
        AI RESPONSE: {response}
        
        CRITICAL: You MUST respond ONLY in English. Never use any other language.
        If the conversation is in another language, understand it but respond in English.
        
        Extract and categorize information into:
        
        1. SHORT-TERM MEMORY (current conversation context):
           - Current topic being discussed
           - Recent context that helps understand the conversation flow
           - Temporary information relevant to this session
           - Keep it concise and relevant
        
        2. LONG-TERM MEMORY (important user information):
           - User's name, preferences, important details
           - Significant facts about the user
           - Important relationships or context
           - Information worth remembering for future conversations
           - Only include truly important information
        
        Rules:
        - If no important information is found, return empty strings
        - Keep memories concise and factual
        - Don't include generic information
        - Focus on what would be useful for future conversations
        - Separate short-term and long-term clearly
        - ALWAYS write memory in English, regardless of the original language
        
        Return in this format:
        SHORT_TERM: [extracted short-term memory or empty]
        LONG_TERM: [extracted long-term memory or empty]
        """
        
        logger.info("‚úÖ MemoryAnalyzer initialized with Gemini API")
    
    async def analyze_conversation(self, prompt: str, response: str) -> Tuple[str, str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∏–∞–ª–æ–≥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏.
        
        Args:
            prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            response: –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (short_memory, long_memory)
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_prompt = self.analysis_prompt_template.format(
                prompt=prompt,
                response=response
            )
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=genai.types.GenerationConfig(
                    temperature=self.temperature,
                    max_output_tokens=1024,
                )
            )
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥
            logger.debug(f"üß† Analyzing conversation for memory extraction...")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            response_obj = await asyncio.to_thread(
                model.generate_content,
                analysis_prompt
            )
            
            if not response_obj or not response_obj.text:
                logger.warning("‚ö†Ô∏è Empty response from Gemini for memory analysis")
                return "", ""
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            short_memory, long_memory = self._parse_analysis_response(response_obj.text)
            
            logger.info(f"üß† Memory analysis completed: short-term ({len(short_memory)} chars), long-term ({len(long_memory)} chars)")
            
            return short_memory, long_memory
            
        except Exception as e:
            logger.error(f"‚ùå Error analyzing conversation for memory: {e}")
            return "", ""
    
    def _parse_analysis_response(self, response_text: str) -> Tuple[str, str]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç Gemini –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏.
        
        Args:
            response_text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (short_memory, long_memory)
        """
        try:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã SHORT_TERM: –∏ LONG_TERM:
            short_term_match = re.search(r'SHORT_TERM:\s*(.*?)(?=LONG_TERM:|$)', response_text, re.DOTALL | re.IGNORECASE)
            long_term_match = re.search(r'LONG_TERM:\s*(.*?)$', response_text, re.DOTALL | re.IGNORECASE)
            
            short_memory = ""
            long_memory = ""
            
            if short_term_match:
                short_memory = short_term_match.group(1).strip()
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
                short_memory = re.sub(r'\s+', ' ', short_memory)
            
            if long_term_match:
                long_memory = long_term_match.group(1).strip()
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
                long_memory = re.sub(r'\s+', ' ', long_memory)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–º—è—Ç—å –Ω–µ –ø—É—Å—Ç–∞—è –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
            if short_memory.lower() in ['empty', 'none', 'no information', '']:
                short_memory = ""
            
            if long_memory.lower() in ['empty', 'none', 'no information', '']:
                long_memory = ""
            
            logger.debug(f"üß† Parsed memory - Short: '{short_memory[:100]}...', Long: '{long_memory[:100]}...'")
            
            return short_memory, long_memory
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing memory analysis response: {e}")
            return "", ""
    
    def is_available(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
        
        Returns:
            True –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ
        """
        return GEMINI_AVAILABLE and self.api_key is not None
